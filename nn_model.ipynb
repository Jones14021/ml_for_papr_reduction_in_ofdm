{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load training data from .dat files\n",
    "raw_data_imaginary_x.dat --> train_imag\n",
    "raw_data_real_x.dat      --> train_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if IS_TRAINING == True, a new model will be compiled \n",
    "# and trained from the dataset\n",
    "#\n",
    "# if IS_TRAINING == False, an existing model will be \n",
    "# loaded and tested against the dataset\n",
    "IS_TRAINING = True\n",
    "\n",
    "# trainingset to be trained or loaded\n",
    "trainingset_number = 5\n",
    "\n",
    "# training params\n",
    "neuron_number = 8\n",
    "activation_function = 'tanh'\n",
    "iterations = 20000\n",
    "learning_rate= 1e-4\n",
    "\n",
    "checkpoint_path = \"./training_\" + str(trainingset_number) + \"/cp_test.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_raw_data_real = \"raw_data_real_\" + str(trainingset_number) + \".dat\"\n",
    "filename_raw_data_imag = \"raw_data_imaginary_\" + str(trainingset_number) + \".dat\"\n",
    "\n",
    "filename_dataset_csv = \"training_data_\" + str(trainingset_number) + \".csv\"\n",
    "\n",
    "\n",
    "dataset = tf.data.experimental.CsvDataset(\n",
    "  filename_dataset_csv,\n",
    "  [tf.float32,  # Required field, use dtype or empty tensor\n",
    "   tf.float32,\n",
    "   tf.float32,\n",
    "   tf.float32\n",
    "  ],\n",
    "  header=True,\n",
    "  select_cols=[0,1,2,3]  \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CsvDatasetV2 element_spec=(TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>\n",
      "(0.09036217, -0.2613757, 0.22294177, 0.1604512)\n",
      "(0.022515569, -0.1132093, 0.16743372, 0.06361104)\n",
      "(0.114548385, -0.100870565, 0.12522025, -0.011140993)\n",
      "(0.049135324, -0.014699027, 0.098613776, -0.06175121)\n",
      "(-0.13331392, -0.12705529, 0.087487355, -0.089262664)\n",
      "(0.1544656, -0.3077073, 0.089055814, -0.09597649)\n",
      "(0.11328178, -0.026650935, 0.09796924, -0.08606317)\n",
      "(0.27299157, -0.015948214, 0.10823633, -0.06591184)\n",
      "(0.15798786, 0.18548791, 0.11556848, -0.042117316)\n",
      "(0.11445405, 0.01783486, 0.11829203, -0.018676687)\n",
      "(0.06248361, -0.12510371, 0.116487764, 0.0037648869)\n"
     ]
    }
   ],
   "source": [
    "def show_dataset_structure():\n",
    "\n",
    "  print(dataset)\n",
    "  i = 0\n",
    "\n",
    "  for element in dataset.as_numpy_iterator():\n",
    "    print(element)\n",
    "    i = i + 1\n",
    "    if i > 10:\n",
    "        break\n",
    "\n",
    "show_dataset_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset element_spec=(TensorSpec(shape=(2,), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.float32, name=None))>\n",
      "(array([ 0.09036217, -0.2613757 ], dtype=float32), array([0.22294177, 0.1604512 ], dtype=float32))\n",
      "(array([ 0.02251557, -0.1132093 ], dtype=float32), array([0.16743372, 0.06361104], dtype=float32))\n",
      "(array([ 0.11454839, -0.10087056], dtype=float32), array([ 0.12522025, -0.01114099], dtype=float32))\n",
      "(array([ 0.04913532, -0.01469903], dtype=float32), array([ 0.09861378, -0.06175121], dtype=float32))\n",
      "(array([-0.13331392, -0.12705529], dtype=float32), array([ 0.08748735, -0.08926266], dtype=float32))\n",
      "(array([ 0.1544656, -0.3077073], dtype=float32), array([ 0.08905581, -0.09597649], dtype=float32))\n",
      "(array([ 0.11328178, -0.02665094], dtype=float32), array([ 0.09796924, -0.08606317], dtype=float32))\n",
      "(array([ 0.27299157, -0.01594821], dtype=float32), array([ 0.10823633, -0.06591184], dtype=float32))\n",
      "(array([0.15798786, 0.18548791], dtype=float32), array([ 0.11556848, -0.04211732], dtype=float32))\n",
      "(array([0.11445405, 0.01783486], dtype=float32), array([ 0.11829203, -0.01867669], dtype=float32))\n",
      "(array([ 0.06248361, -0.12510371], dtype=float32), array([0.11648776, 0.00376489], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# transform dataset\n",
    "def transform_func(element1, element2, element3, element4):\n",
    "    result = ([element1, element2], [element3, element4])\n",
    "    #result = (element1, element3)\n",
    "    return result\n",
    "\n",
    "# element now has format\n",
    "# (input_re input_imag), (output_re output_imag)\n",
    "\n",
    "dataset = dataset.map(transform_func)\n",
    "\n",
    "show_dataset_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_TRAINING:\n",
    "    FC_layer = tf.keras.layers.Dense(units=neuron_number, activation=activation_function) # dense layer == fully connected layer    \n",
    "\n",
    "    #input_layer = tf.keras.layers.InputLayer()\n",
    "\n",
    "    #reshape_layer = tf.keras.layers.Reshape()\n",
    "\n",
    "    input_layer = tf.keras.layers.Dense(units=1, input_shape=(None,2))\n",
    "    output_layer = tf.keras.layers.Dense(units=2, activation=activation_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "if IS_TRAINING:\n",
    "    model = tf.keras.Sequential([input_layer, FC_layer, output_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "# as described in article: MSE mean squared error\n",
    "# batches have the format:\n",
    "# [batch_real, batch_imag]\n",
    "def my_loss_fcn(ground_truth_batch, predicted_batch):\n",
    "    result = tf.square(predicted_batch[:,1] - ground_truth_batch[:,1])\n",
    "    result = result + tf.square(predicted_batch[:,2] - ground_truth_batch[:,2])\n",
    "    N = len(ground_truth_batch)\n",
    "    result = tf.reduce_sum(result,1) / N\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully compiled new model.\n"
     ]
    }
   ],
   "source": [
    "# compile the keras model\n",
    "# loss=tf.keras.losses.MeanSquaredError()\n",
    "if IS_TRAINING:\n",
    "    model.compile(loss=my_loss_fcn, \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate), \n",
    "    metrics=['accuracy',\n",
    "    tf.keras.metrics.RootMeanSquaredError()])    \n",
    "\n",
    "    print(\"Successfully compiled new model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from file if not training\n",
    "if not IS_TRAINING:\n",
    "    model = tf.keras.models.load_model(\"./training_\" + str(trainingset_number) + \"/saved_trained_model\")\n",
    "    print(\"Successfully loaded existing model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, None, 1)           3         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, None, 8)           16        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, None, 2)           18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# This may generate warnings related to saving the state of the optimizer.\n",
    "# These warnings (and similar warnings throughout this notebook)\n",
    "# are in place to discourage outdated usage, and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 2) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 2), dtype=tf.float32, name='dense_50_input'), name='dense_50_input', description=\"created by layer 'dense_50_input'\"), but it was called on an input with incompatible shape (2,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_13\" (type Sequential).\n    \n    Input 0 of layer \"dense_50\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (2,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(2,), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonas\\OneDrive\\Dokumente\\Airbus_Helicopters\\DHBW\\TEN19\\Studienarbeit\\source_code_omar_project\\nn_model.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=0'>1</a>\u001b[0m \u001b[39m# fit the keras model on the dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=2'>3</a>\u001b[0m \u001b[39m# train the model by slicing the data into \"batches\" of size batch_size,\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=3'>4</a>\u001b[0m \u001b[39m# and repeatedly iterating over the entire dataset \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=4'>5</a>\u001b[0m \u001b[39m# for a given number of epochs\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m IS_TRAINING:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=6'>7</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Dokumente/Airbus_Helicopters/DHBW/TEN19/Studienarbeit/source_code_omar_project/nn_model.ipynb#ch0000013?line=7'>8</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49miterations)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jonas/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_13\" (type Sequential).\n    \n    Input 0 of layer \"dense_50\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (2,)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(2,), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit the keras model on the dataset\n",
    "#\n",
    "# train the model by slicing the data into \"batches\" of size batch_size,\n",
    "# and repeatedly iterating over the entire dataset \n",
    "# for a given number of epochs\n",
    "if IS_TRAINING:\n",
    "    history = model.fit(dataset, \n",
    "    epochs=iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the dataset against the loaded model\n",
    "if not IS_TRAINING:\n",
    "    model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model in the correct directory\n",
    "if IS_TRAINING:\n",
    "    model.save(\"./training_\" + str(trainingset_number) + \"/saved_trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The returned history object holds a record of the loss values \n",
    "# and metric values during training\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training progress\n",
    "# diagram number 2 paper page 4\n",
    "\n",
    "# cost function mean square error"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "683e9bbf599fde3b00e37a0db68ad40a268db525b46af3924c3427b16ddb8792"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
